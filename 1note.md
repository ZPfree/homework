模型介绍
InternLM
轻量级:InternLM-7B
70亿模型参数，小巧轻便，便于部署，
10000亿训练token数据，
信息全面，能力多维，
具备长语境能力，支持8k语境窗口长度，
具备通用工具调用能力，支持多种工具调用模板。

中量级:InternLM-20B
200亿参数量，在模型能力与推理代价间取得平衡，
采用深而窄的结构，降低推理计算量但提高了推理能力，
4k训练语境长度，推理时可外推至16k。

重量级:InternLM-123B
1230亿模型参数，强大的性能，
具备极强的推理能力、全面的知识覆盖面、超强理解能力与对话能力，
准确的API调用能力，可实现各类Agent。
全链接工具介绍。
OpenCompass：面向大模型评测的一站式平台
IMDeploy：涵盖了 LLM 任务的全套轻量化、部署和服务解决方案的高效推理工具箱
XTuner：轻量级微调大语言模型的工具库
InternLM-XComposer：浦语·灵笔，基于书生·浦语大语言模型研发的视觉-语言大模型
Lagent：一个轻量级、开源的基于大语言模型的智能体（agent）框架
InternLM：一个开源的轻量级训练框架，旨在支持大模型训练而无需大量的依赖
